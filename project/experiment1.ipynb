{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import kurtosis\n",
    "import pandas as pd\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pendigits dataset loaded successfully with shape: (10992, 16)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(name):\n",
    "    if name.lower() == 'satellite':\n",
    "        url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.trn\"\n",
    "        if not os.path.exists('sat.trn'):\n",
    "            urlretrieve(url, 'sat.trn')\n",
    "        \n",
    "        data = pd.read_csv('sat.trn', sep=' ', header=None)\n",
    "        \n",
    "        X = data.iloc[:, :-1].values\n",
    "        y_orig = data.iloc[:, -1].values\n",
    "        \n",
    "        y = np.where(y_orig == 2, -1, 1)\n",
    "        \n",
    "    elif name.lower() == 'annthyroid':\n",
    "        with open('data/Annthyroid_withoutdupl_norm_07.arff', 'r') as f:\n",
    "            dataset = arff.load(f)\n",
    "            \n",
    "        df = pd.DataFrame(dataset['data'], columns=[attr[0] for attr in dataset['attributes']])\n",
    "        y = df['outlier'].map({'yes': -1, 'no': 1}).values\n",
    "        X = df.drop(['id', 'outlier'], axis=1).astype(float).values\n",
    "        \n",
    "    elif name.lower() == 'pendigits':\n",
    "        train_data = pd.read_csv('data/pendigits_dyn_train.csv', header=None)\n",
    "        test_data = pd.read_csv('data/pendigits_dyn_test.csv', header=None)\n",
    "        train_labels = pd.read_csv('data/pendigits_label_train.csv', header=None)\n",
    "        test_labels = pd.read_csv('data/pendigits_label_test.csv', header=None)\n",
    "        \n",
    "        X = np.vstack([train_data.values, test_data.values])\n",
    "        y_orig = np.concatenate([train_labels.values.ravel(), test_labels.values.ravel()])\n",
    "        \n",
    "        y = np.where(y_orig == 8, -1, 1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = load_dataset('pendigits')\n",
    "print(\"pendigits dataset loaded successfully with shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomIsolationForest:\n",
    "    def __init__(self, n_estimators=100, max_samples='auto', contamination=0.1, \n",
    "                 random_state=None, splitting_criterion='random'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.contamination = contamination\n",
    "        self.random_state = random_state\n",
    "        self.splitting_criterion = splitting_criterion\n",
    "        \n",
    "    def _calculate_pooled_gain(self, X, feature):\n",
    "        sorted_x = np.sort(X[:, feature])\n",
    "        n = len(sorted_x)\n",
    "        if n <= 1:\n",
    "            return 0\n",
    "        \n",
    "        splits = (sorted_x[1:] + sorted_x[:-1]) / 2\n",
    "        \n",
    "        max_gain = 0\n",
    "        for split in splits:\n",
    "            left_mask = X[:, feature] <= split\n",
    "            right_mask = ~left_mask\n",
    "            \n",
    "            if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:\n",
    "                continue\n",
    "                \n",
    "            left_std = np.std(X[left_mask], axis=0).mean()\n",
    "            right_std = np.std(X[right_mask], axis=0).mean()\n",
    "            total_std = np.std(X, axis=0).mean()\n",
    "            \n",
    "            if total_std == 0:\n",
    "                continue\n",
    "            \n",
    "            n_left = np.sum(left_mask)\n",
    "            n_right = np.sum(right_mask)\n",
    "            \n",
    "            gain = (total_std - (n_left * left_std + n_right * right_std) / (n_left + n_right)) / total_std\n",
    "            max_gain = max(max_gain, gain)\n",
    "            \n",
    "        return max_gain\n",
    "\n",
    "    def fit_predict(self, X):\n",
    "        if self.splitting_criterion == 'random':\n",
    "            clf = IsolationForest(\n",
    "                n_estimators=self.n_estimators,\n",
    "                max_samples=100,\n",
    "                contamination=self.contamination,\n",
    "                random_state=self.random_state\n",
    "            )\n",
    "            return clf.fit_predict(X)\n",
    "        \n",
    "        elif self.splitting_criterion in ['kurtosis', 'pooled_gain']:\n",
    "            scores = np.zeros(X.shape[0])\n",
    "            \n",
    "            for _ in range(self.n_estimators):\n",
    "                if isinstance(self.max_samples, str) and self.max_samples == 'auto':\n",
    "                    sample_size = min(256, X.shape[0])\n",
    "                else:\n",
    "                    sample_size = self.max_samples\n",
    "                    \n",
    "                indices = np.random.choice(X.shape[0], size=sample_size, replace=False)\n",
    "                X_sample = X[indices]\n",
    "                \n",
    "                feature_scores = []\n",
    "                for feature in range(X.shape[1]):\n",
    "                    if self.splitting_criterion == 'kurtosis':\n",
    "                        try:\n",
    "                            score = abs(kurtosis(X_sample[:, feature]))\n",
    "                            if np.isnan(score) or np.isinf(score):\n",
    "                                score = 0\n",
    "                        except:\n",
    "                            score = 0\n",
    "                    else:  # pooled_gain\n",
    "                        score = self._calculate_pooled_gain(X_sample, feature)\n",
    "                    feature_scores.append(score)\n",
    "                \n",
    "                if self.splitting_criterion == 'kurtosis':\n",
    "                    feature_scores = np.array(feature_scores)\n",
    "                    if np.sum(feature_scores) == 0:\n",
    "                        probs = np.ones(len(feature_scores)) / len(feature_scores)\n",
    "                    else:\n",
    "                        probs = feature_scores + 1e-10\n",
    "                        probs = probs / probs.sum()\n",
    "                    selected_feature = np.random.choice(X.shape[1], p=probs)\n",
    "                else:\n",
    "                    selected_feature = np.argmax(feature_scores)\n",
    "                \n",
    "                feature_data = X[:, [selected_feature]]\n",
    "                tree = IsolationForest(n_estimators=1, max_samples=sample_size,\n",
    "                                     random_state=self.random_state)\n",
    "                scores += tree.fit_predict(feature_data)\n",
    "            \n",
    "            scores /= self.n_estimators\n",
    "            threshold = np.percentile(scores, self.contamination * 100)\n",
    "            return np.where(scores <= threshold, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training random on satellite dataset....\n",
      "Training kurtosis on satellite dataset....\n",
      "Training pooled_gain on satellite dataset....\n",
      "Training random on annthyroid dataset....\n",
      "Training kurtosis on annthyroid dataset....\n",
      "Training pooled_gain on annthyroid dataset....\n",
      "Training random on pendigits dataset....\n",
      "Training kurtosis on pendigits dataset....\n",
      "Training pooled_gain on pendigits dataset....\n",
      "\n",
      "Results (AUC scores):\n",
      "Method      kurtosis  random  pooled_gain\n",
      "Dataset                                  \n",
      "annthyroid     0.657   0.561        0.573\n",
      "pendigits      0.516   0.705        0.734\n",
      "satellite      0.784   0.919        0.801\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "def run_experiment():\n",
    "    datasets = ['satellite', 'annthyroid', 'pendigits']\n",
    "    methods = ['random', 'kurtosis']\n",
    "    results = []\n",
    "    \n",
    "    warnings.filterwarnings('ignore', category=RuntimeWarning, \n",
    "                          message='Precision loss occurred in moment calculation.*')\n",
    "    \n",
    "    for dataset_name in datasets:\n",
    "        X, y = load_dataset(dataset_name)\n",
    "        contamination = np.mean(y == -1)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        for method in methods:\n",
    "            print(f\"Training {method} on {dataset_name} dataset....\")\n",
    "            \n",
    "            clf = CustomIsolationForest(\n",
    "                n_estimators=100,\n",
    "                contamination=contamination,\n",
    "                random_state=42,\n",
    "                splitting_criterion=method,\n",
    "            )\n",
    "            \n",
    "            y_pred = clf.fit_predict(X)\n",
    "            y_pred_scores = -y_pred\n",
    "            auc = roc_auc_score(y == -1, y_pred_scores)\n",
    "            \n",
    "            results.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'Method': method,\n",
    "                'AUC': auc\n",
    "            })\n",
    "\n",
    "    warnings.resetwarnings()\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "results_df = run_experiment()\n",
    "\n",
    "pivoted_df = results_df.pivot(index='Dataset', columns='Method', values='AUC')\n",
    "\n",
    "print(\"\\nResults (AUC scores):\")\n",
    "print(pivoted_df\n",
    "      .round(3)  \n",
    "      .to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
